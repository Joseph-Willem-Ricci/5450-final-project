{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Setup\n",
    "Save the following datasets locally as:\n",
    "\n",
    "charts.csv: https://www.kaggle.com/datasets/dhruvildave/spotify-charts (2017-2021)\n",
    "\n",
    "tracks_features.csv: https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs\n",
    "\n",
    "Spotify 2010 - 2019 Top 100.csv: https://www.kaggle.com/datasets/muhmores/spotify-top-100-songs-of-20152019\n",
    "\n",
    "spotify_dataset.csv: https://www.kaggle.com/datasets/sashankpillai/spotify-top-200-charts-20202021\n",
    "\n",
    "dataset.csv: https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset\n",
    "\n",
    "data.csv: https://www.kaggle.com/datasets/vatsalmavani/spotify-dataset\n",
    "\n",
    "SpotifyFeatures.csv: https://www.kaggle.com/datasets/nandhakumarss/spotify-song-tracks\n",
    "\n",
    "train.csv and test.csv: https://www.kaggle.com/datasets/elemento/music-albums-popularity-prediction?select=test.csv\n",
    "\n",
    "TikTok_songs_2019.csv: https://www.kaggle.com/datasets/sveta151/tiktok-popular-songs-2019\n",
    "\n",
    "TikTok_songs_2020.csv: https://www.kaggle.com/datasets/sveta151/tiktok-popular-songs-2020\n",
    "\n",
    "TikTok_songs_2021.csv: https://www.kaggle.com/datasets/sveta151/tiktok-popular-songs-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandasql in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandasql) (1.21.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandasql) (1.3.5)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandasql) (2.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->pandasql) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->pandasql) (2021.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sqlalchemy->pandasql) (4.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sqlalchemy->pandasql) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Joe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# package installs and imports\n",
    "%pip install pandasql  \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pandas dataframes\n",
    "charts_df = pd.read_csv('charts.csv')\n",
    "song_features_1_df = pd.read_csv('tracks_features.csv')\n",
    "song_features_2_df = pd.read_csv('Spotify 2010 - 2019 Top 100.csv')\n",
    "song_features_3_df = pd.read_csv('spotify_dataset.csv')\n",
    "song_features_4_df = pd.read_csv('dataset.csv')\n",
    "song_features_5_df = pd.read_csv('data.csv')\n",
    "song_features_6_df = pd.read_csv('SpotifyFeatures.csv')\n",
    "song_features_7_df = pd.read_csv('train.csv')\n",
    "song_features_10_df = pd.read_csv('test.csv')\n",
    "tiktok_19_df = pd.read_csv('TikTok_songs_2019.csv')\n",
    "tiktok_20_df = pd.read_csv('TikTok_songs_2020.csv')\n",
    "tiktok_21_df = pd.read_csv('TikTok_songs_2021.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Feature EDA\n",
    "\n",
    "Exploring the many possible datasets of songs and features. Relevant questions to answer:\n",
    "\n",
    "1. Can we find song features for most of the songs in 'charts.csv'?\n",
    "\n",
    "2. Do we have to combine datasets to do so?\n",
    "\n",
    "3. If we have to combine datasets, what fields do they share?\n",
    "\n",
    "4. What kind of and how much cleaning do we need to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_features_1_df match percentage: 5.41\n",
      "song_features_2_df match percentage: 0.3\n",
      "song_features_3_df match percentage: 0.79\n",
      "song_features_4_df match percentage: 3.65\n",
      "song_features_5_df match percentage: 6.25\n",
      "song_features_6_df match percentage: 7.14\n",
      "song_features_7_df match percentage: 2.7\n",
      "song_features_8_df match percentage: 1.26\n",
      "song_features_9_df match percentage: 1.08\n",
      "song_features_10_df match percentage: 0.87\n",
      "song_features_11_df match percentage: 0.52\n",
      "song_features_12_df match percentage: 0.46\n",
      "combined features match percentage: 17.58\n",
      "for a total of 34720 out of 197535 songs\n"
     ]
    }
   ],
   "source": [
    "# first, since we want to find song features for as many of the songs in 'charts_df' as possible, let's start by\n",
    "# projecting and grouping charts_df by song title and artist name\n",
    "charts_songs_artists_df = charts_df[['title', 'artist']].drop_duplicates()\n",
    "\n",
    "# next, let's join the features datasets on song title and artist name and see what percentage of songs in charts_df\n",
    "# each song features dataset can provide features for\n",
    "song_features_1_df['artists'] = song_features_1_df['artists'].str.replace('[', '').str.replace(']', '').str.replace(\"'\", '')\n",
    "song_features_1_df_projected = song_features_1_df[['name', 'artists']].rename(columns={'name': 'title', 'artists': 'artist'})\n",
    "song_features_2_df_projected = song_features_2_df[['title', 'artist']]\n",
    "song_features_3_df_projected = song_features_3_df[['Song Name', 'Artist']].rename(columns={'Song Name': 'title', 'Artist': 'artist'})\n",
    "song_features_4_df_projected = song_features_4_df[['track_name', 'artists']].rename(columns={'track_name': 'title', 'artists': 'artist'})\n",
    "song_features_5_df['artists'] = song_features_5_df['artists'].str.replace('[', '').str.replace(']', '').str.replace(\"'\", '')\n",
    "song_features_5_df_projected = song_features_5_df[['name', 'artists']].rename(columns={'name': 'title', 'artists': 'artist'})\n",
    "song_features_6_df_projected = song_features_6_df[['track_name', 'artist_name']].rename(columns={'track_name': 'title', 'artist_name': 'artist'})\n",
    "song_features_7_df['artists'] = song_features_7_df['artists'].str.replace(', ', '')  # contains three songs per album, so build 7 8 and 9 below\n",
    "song_features_7_df_projected = song_features_7_df[['t_name0', 'artists']].rename(columns={'t_name0': 'title', 'artists': 'artist'})\n",
    "song_features_8_df_projected = song_features_7_df[['t_name1', 'artists']].rename(columns={'t_name1': 'title', 'artists': 'artist'})\n",
    "song_features_9_df_projected = song_features_7_df[['t_name2', 'artists']].rename(columns={'t_name2': 'title', 'artists': 'artist'})\n",
    "song_features_10_df['artists'] = song_features_10_df['artists'].str.replace(', ', '')  # contains three songs per album, so build 10 11 and 12 below\n",
    "song_features_10_df_projected = song_features_10_df[['t_name0', 'artists']].rename(columns={'t_name0': 'title', 'artists': 'artist'})\n",
    "song_features_11_df_projected = song_features_10_df[['t_name1', 'artists']].rename(columns={'t_name1': 'title', 'artists': 'artist'})\n",
    "song_features_12_df_projected = song_features_10_df[['t_name2', 'artists']].rename(columns={'t_name2': 'title', 'artists': 'artist'})\n",
    "\n",
    "# join song features datasets on song title and artist name\n",
    "merge_1 = pd.merge(charts_songs_artists_df, song_features_1_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_2 = pd.merge(charts_songs_artists_df, song_features_2_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_3 = pd.merge(charts_songs_artists_df, song_features_3_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_4 = pd.merge(charts_songs_artists_df, song_features_4_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_5 = pd.merge(charts_songs_artists_df, song_features_5_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_6 = pd.merge(charts_songs_artists_df, song_features_6_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_7 = pd.merge(charts_songs_artists_df, song_features_7_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_8 = pd.merge(charts_songs_artists_df, song_features_8_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_9 = pd.merge(charts_songs_artists_df, song_features_9_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_10 = pd.merge(charts_songs_artists_df, song_features_10_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_11 = pd.merge(charts_songs_artists_df, song_features_11_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "merge_12 = pd.merge(charts_songs_artists_df, song_features_12_df_projected, on=['title', 'artist'], how='inner').drop_duplicates()\n",
    "\n",
    "\n",
    "match_percentage_1 = 100 * merge_1.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_2 = 100 * merge_2.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_3 = 100 * merge_3.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_4 = 100 * merge_4.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_5 = 100 * merge_5.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_6 = 100 * merge_6.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_7 = 100 * merge_7.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_8 = 100 * merge_8.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_9 = 100 * merge_9.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_10 = 100 * merge_10.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_11 = 100 * merge_11.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_12 = 100 * merge_12.shape[0] / charts_songs_artists_df.shape[0]\n",
    "\n",
    "print(\"song_features_1_df match percentage: \" + str(round(match_percentage_1,2)))\n",
    "print(\"song_features_2_df match percentage: \" + str(round(match_percentage_2,2)))\n",
    "print(\"song_features_3_df match percentage: \" + str(round(match_percentage_3,2)))\n",
    "print(\"song_features_4_df match percentage: \" + str(round(match_percentage_4,2)))\n",
    "print(\"song_features_5_df match percentage: \" + str(round(match_percentage_5,2)))\n",
    "print(\"song_features_6_df match percentage: \" + str(round(match_percentage_6,2)))\n",
    "print(\"song_features_7_df match percentage: \" + str(round(match_percentage_7,2)))\n",
    "print(\"song_features_8_df match percentage: \" + str(round(match_percentage_8,2)))\n",
    "print(\"song_features_9_df match percentage: \" + str(round(match_percentage_9,2)))\n",
    "print(\"song_features_10_df match percentage: \" + str(round(match_percentage_10,2)))\n",
    "print(\"song_features_11_df match percentage: \" + str(round(match_percentage_11,2)))\n",
    "print(\"song_features_12_df match percentage: \" + str(round(match_percentage_12,2)))\n",
    "\n",
    "combined_features_df = pd.concat([merge_1, merge_2, merge_3, merge_4, merge_5, merge_6, merge_7, merge_8, merge_9, merge_10, merge_11, merge_12], ignore_index=True).drop_duplicates()\n",
    "match_percentage_combined = 100 * combined_features_df.shape[0] / charts_songs_artists_df.shape[0]\n",
    "print(\"combined features match percentage: \" + str(round(match_percentage_combined,2)))\n",
    "print(\"for a total of \" + str(combined_features_df.shape[0]) + \" out of \" + str(charts_songs_artists_df.shape[0]) + \" songs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
