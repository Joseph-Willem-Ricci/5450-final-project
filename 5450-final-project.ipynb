{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Setup\n",
    "Save the following datasets locally as:\n",
    "\n",
    "charts.csv: https://www.kaggle.com/datasets/dhruvildave/spotify-charts\n",
    "\n",
    "Spotify 1.2M+ Songs.csv: https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs\n",
    "\n",
    "Spotify Top 100 Songs of 2010-2019.csv: https://www.kaggle.com/datasets/muhmores/spotify-top-100-songs-of-20152019\n",
    "\n",
    "Spotify Top 200 Charts (2020-2021).csv: https://www.kaggle.com/datasets/sashankpillai/spotify-top-200-charts-20202021\n",
    "\n",
    "Spotify Tracks Dataset.csv: https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset\n",
    "\n",
    "TikTok_songs_2019.csv: https://www.kaggle.com/datasets/sveta151/tiktok-popular-songs-2019\n",
    "\n",
    "TikTok_songs_2020.csv: https://www.kaggle.com/datasets/sveta151/tiktok-popular-songs-2020\n",
    "\n",
    "TikTok_songs_2021.csv: https://www.kaggle.com/datasets/sveta151/tiktok-popular-songs-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandasql in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandasql) (1.21.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandasql) (1.3.5)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandasql) (2.0.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->pandasql) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->pandasql) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sqlalchemy->pandasql) (4.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sqlalchemy->pandasql) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Joe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# package installs and imports\n",
    "%pip install pandasql  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pandas dataframes\n",
    "charts_df = pd.read_csv('charts.csv')\n",
    "song_features_1_df = pd.read_csv('Spotify 1.2M+ Songs.csv')\n",
    "song_features_2_df = pd.read_csv('Spotify Top 100 Songs of 2010-2019.csv')\n",
    "song_features_3_df = pd.read_csv('Spotify Top 200 Charts (2020-2021).csv')\n",
    "song_features_4_df = pd.read_csv('Spotify Tracks Dataset.csv')\n",
    "tiktok_19_df = pd.read_csv('TikTok_songs_2019.csv')\n",
    "tiktok_20_df = pd.read_csv('TikTok_songs_2020.csv')\n",
    "tiktok_21_df = pd.read_csv('TikTok_songs_2021.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Feature EDA\n",
    "\n",
    "Exploring the many possible datasets of songs and features. Relevant questions to answer:\n",
    "\n",
    "1. Can we find song features for most of the songs in 'charts.csv'?\n",
    "\n",
    "2. Do we have to combine datasets to do so?\n",
    "\n",
    "3. If we have to combine datasets, what fields do they share?\n",
    "\n",
    "4. What kind of and how much cleaning do we need to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.31792156247310577\n",
      "0.7867039937630674\n",
      "7.569368156206811\n"
     ]
    }
   ],
   "source": [
    "# first, since we want to find song features for as many of the songs in 'charts_df' as possible, let's start by\n",
    "# projecting and grouping charts_df by song title and artist name\n",
    "charts_songs_artists_df = charts_df[['title', 'artist']].groupby(['title', 'artist']).max()\n",
    "\n",
    "# next, let's join the features datasets on song title and artist name and see what percentage of songs in charts_df\n",
    "# each song features dataset can provide features for\n",
    "song_features_1_df_projected = song_features_1_df[['name', 'artists']].rename(columns={'name': 'title', 'artists': 'artist'})\n",
    "song_features_2_df_projected = song_features_2_df[['title', 'artist']]\n",
    "song_features_3_df_projected = song_features_3_df[['Song Name', 'Artist']].rename(columns={'Song Name': 'title', 'Artist': 'artist'})\n",
    "song_features_4_df_projected = song_features_4_df[['track_name', 'artists']].rename(columns={'track_name': 'title', 'artists': 'artist'})\n",
    "\n",
    "# join song features datasets on song title and artist name\n",
    "merge_1 = pd.merge(charts_songs_artists_df, song_features_1_df_projected, on=['title', 'artist'], how='inner')\n",
    "merge_2 = pd.merge(charts_songs_artists_df, song_features_2_df_projected, on=['title', 'artist'], how='inner')\n",
    "merge_3 = pd.merge(charts_songs_artists_df, song_features_3_df_projected, on=['title', 'artist'], how='inner')\n",
    "merge_4 = pd.merge(charts_songs_artists_df, song_features_4_df_projected, on=['title', 'artist'], how='inner')\n",
    "\n",
    "match_percentage_1 = 100 * merge_1.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_2 = 100 * merge_2.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_3 = 100 * merge_3.shape[0] / charts_songs_artists_df.shape[0]\n",
    "match_percentage_4 = 100 * merge_4.shape[0] / charts_songs_artists_df.shape[0]\n",
    "\n",
    "print(match_percentage_1)\n",
    "print(match_percentage_2)\n",
    "print(match_percentage_3)\n",
    "print(match_percentage_4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
