{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joseph-Willem-Ricci/5450-final-project/blob/Juan/CIS5450_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5RzHfJIP-OW"
      },
      "source": [
        "# CIT 5450 Final Project\n",
        "Joanne Crean, Juan Goleniowski, Joseph Ricci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgvinkN7Qm8e"
      },
      "source": [
        "Before running, be sure to create a new Kaggle API token and save it as 'kaggle.json' in your default Google Drive location (/content/drive/MyDrive/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTHg3UfjQbIp"
      },
      "outputs": [],
      "source": [
        "# Installs\n",
        "!pip install -q kaggle\n",
        "!pip install pandasql\n",
        "!pip install sqlalchemy==1.4.46"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwAn5PY1_KU6"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import pandasql as ps\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q53w-KnA7wi"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "drive.mount('/content/drive')\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxzLvzzIB-fi"
      },
      "outputs": [],
      "source": [
        "# Download Datasets\n",
        "# Spotify Top 200 and Viral 50 Charts for 2017 through 2021 Dataset\n",
        "!!kaggle datasets download -d dhruvildave/spotify-charts\n",
        "\n",
        "# Spotify Audio Features Datasets\n",
        "!!kaggle datasets download -d rodolfofigueroa/spotify-12m-songs\n",
        "!!kaggle datasets download -d muhmores/spotify-top-100-songs-of-20152019\n",
        "!!kaggle datasets download -d sashankpillai/spotify-top-200-charts-20202021\n",
        "!!kaggle datasets download -d maharshipandya/-spotify-tracks-dataset\n",
        "!!kaggle datasets download -d vatsalmavani/spotify-dataset\n",
        "!!kaggle datasets download -d nandhakumarss/spotify-song-tracks\n",
        "!!kaggle datasets download -d elemento/music-albums-popularity-prediction\n",
        "\n",
        "# TikTok Popular Songs Dataset\n",
        "!!kaggle datasets download -d sveta151/tiktok-popular-songs-2019\n",
        "!!kaggle datasets download -d sveta151/tiktok-popular-songs-2020\n",
        "!!kaggle datasets download -d sveta151/tiktok-popular-songs-2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WPqLyOGCp8B"
      },
      "outputs": [],
      "source": [
        "# Unzip Datasets\n",
        "!unzip /content/spotify-charts.zip\n",
        "!unzip /content/spotify-12m-songs.zip\n",
        "!unzip /content/spotify-top-100-songs-of-20152019.zip\n",
        "!unzip /content/spotify-top-200-charts-20202021.zip\n",
        "!unzip /content/-spotify-tracks-dataset.zip\n",
        "!unzip /content/spotify-dataset.zip\n",
        "!unzip /content/spotify-song-tracks.zip\n",
        "!unzip /content/music-albums-popularity-prediction.zip\n",
        "!unzip /content/tiktok-popular-songs-2019\n",
        "!unzip /content/tiktok-popular-songs-2020\n",
        "!unzip /content/tiktok-popular-songs-2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AlyHOELYRnS"
      },
      "outputs": [],
      "source": [
        "# Clean up directory to save space\n",
        "!rm sample_data/*\n",
        "!rm -d sample_data\n",
        "!rm ./*.zip\n",
        "!rm sample_solution.csv\n",
        "!rm ./*.xlsx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEbMv8CEQMJG"
      },
      "outputs": [],
      "source": [
        "# Read the csv files and save them to pandas dataframes\n",
        "df_charts = pd.read_csv('charts.csv')\n",
        "df_song_features_1 = pd.read_csv('tracks_features.csv')\n",
        "df_song_features_2 = pd.read_csv('Spotify 2010 - 2019 Top 100.csv')\n",
        "df_song_features_3 = pd.read_csv('spotify_dataset.csv')\n",
        "df_song_features_4 = pd.read_csv('dataset.csv')\n",
        "df_song_features_5 = pd.read_csv('data/data.csv')\n",
        "df_song_features_6 = pd.read_csv('SpotifyFeatures.csv')\n",
        "df_song_features_7 = pd.read_csv('train.csv')\n",
        "df_song_features_10 = pd.read_csv('test.csv')\n",
        "df_tiktok_19 = pd.read_csv('TikTok_songs_2019.csv')\n",
        "df_tiktok_20 = pd.read_csv('TikTok_songs_2020.csv')\n",
        "df_tiktok_21 = pd.read_csv('TikTok_songs_2021.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1epbANjRnzN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsiSHzoWYAfn"
      },
      "outputs": [],
      "source": [
        "# Clean up remaining files\n",
        "!rm data/*\n",
        "!rm -d data\n",
        "!rm ./*.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hmg7zVxaI-6"
      },
      "source": [
        "# Spotify Top 200 and Viral 50 Charts EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv90Vf_y_d_M"
      },
      "outputs": [],
      "source": [
        "# Create a separate column for Year\n",
        "df_charts['Year']=df_charts['date'].str.slice(stop=4)\n",
        "\n",
        "# Cast 'Year' as Int\n",
        "df_charts['Year'] = df_charts['Year'].astype(int)\n",
        "\n",
        "# Show datatypes \n",
        "df_charts.dtypes\n",
        "\n",
        "#remove ID, trend and streams columns\n",
        "df_charts.drop(['url', 'trend', 'streams'], axis=1, inplace=True)\n",
        "\n",
        "df_charts.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJnMPf5uE4gp"
      },
      "outputs": [],
      "source": [
        "# Number of records per year\n",
        "df_charts.groupby(by='Year', as_index=False).count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets the highes ranking achieved by each song in the period 2017-2018 in any country\n",
        "max_ranking_df = df_charts[df_charts['Year']<2019].groupby('title').min('rank')\n"
      ],
      "metadata": {
        "id": "EUUVcbuwRtxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_ranking_df"
      ],
      "metadata": {
        "id": "uB8XYdb0X0f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPnsptwJI-qg"
      },
      "outputs": [],
      "source": [
        "# Remove records with year 2017 and 2018\n",
        "df_charts=df_charts[df_charts['Year'] > 2018]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add max 2017-2018 ranking to df_charts\n",
        "df_charts=df_charts.merge(max_ranking_df[['rank']], left_on=['title'], right_on=['title'], how='left')"
      ],
      "metadata": {
        "id": "SHcEfRJLPm5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename Rank columns\n",
        "df_charts.rename(columns={'rank_x':'rank', 'rank_y':'Best_2017-28'}, inplace=True)"
      ],
      "metadata": {
        "id": "lZaJmOfXTBL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace NaN with 0\n",
        "df_charts['Best_2017-28']=df_charts['Best_2017-28'].fillna(0)"
      ],
      "metadata": {
        "id": "txFfoZg2bvA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best ranking in 2017-2018 for songs in the 2019-2021 group\n",
        "df_charts"
      ],
      "metadata": {
        "id": "6Efl22iLcb1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9a2ZRHIGQ74"
      },
      "outputs": [],
      "source": [
        "# Top 50 artists in the 2019-2021 period by number of days in the top position\n",
        "\n",
        "query = \"\"\"SELECT artist, count(date) as 'days as number 1'\n",
        "FROM df_charts\n",
        "WHERE rank == 1\n",
        "GROUP BY artist\n",
        "ORDER BY count(date) DESC\n",
        "LIMIT 50\n",
        "\"\"\"\n",
        "\n",
        "sql_top_50_artists = ps.sqldf(query, locals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stIirPTbGUkK"
      },
      "outputs": [],
      "source": [
        "sql_top_50_artists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-IYyMNZGZzl"
      },
      "outputs": [],
      "source": [
        "# Top 50 songs in the 2019-2021 period by number of days in the top position\n",
        "\n",
        "query = \"\"\"SELECT title, count(date) as 'days as number 1'\n",
        "FROM df_charts\n",
        "WHERE rank == 1\n",
        "GROUP BY title\n",
        "ORDER BY count(date) DESC\n",
        "LIMIT 50\n",
        "\"\"\"\n",
        "\n",
        "sql_top_50_songs = ps.sqldf(query, locals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWilb77mGall"
      },
      "outputs": [],
      "source": [
        "sql_top_50_songs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 50 longest trending songs in the US in the 2019-2021 period\n",
        "\n",
        "query = \"\"\"SELECT title, count(date) as 'days trending'\n",
        "FROM df_charts\n",
        "WHERE region == 'United States'\n",
        "GROUP BY title\n",
        "ORDER BY count(date) DESC\n",
        "LIMIT 50\n",
        "\"\"\"\n",
        "\n",
        "sql_top_50_longest_trending_songs = ps.sqldf(query, locals())"
      ],
      "metadata": {
        "id": "uazpiIRN3ZQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_top_50_longest_trending_songs"
      ],
      "metadata": {
        "id": "LgACTOPO4hvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 50 longest trending songs outside of the US in the 2019-2021 period\n",
        "\n",
        "query = \"\"\"SELECT title, count(date) as 'days trending'\n",
        "FROM df_charts\n",
        "WHERE region != 'United States'\n",
        "GROUP BY title\n",
        "ORDER BY count(date) DESC\n",
        "LIMIT 50\n",
        "\"\"\"\n",
        "\n",
        "sql_top_50_longest_trending_ROW_songs = ps.sqldf(query, locals())"
      ],
      "metadata": {
        "id": "oeQeR8Ig_Vtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_top_50_longest_trending_ROW_songs"
      ],
      "metadata": {
        "id": "KDou6cwi_50L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfi4tbmeaYPc"
      },
      "source": [
        "# Spotify Audio Feature Dataset EDA\n",
        "\n",
        "Since the Spotify Top 200 and Viral 50 charts dataset does not come with audio features the songs, there is no guarantee that we can find datasets that include audio features for all of the songs in the charts. One relevant question to explore is therefore\n",
        "\n",
        "1. Can we find audio feature data for a suitably \"big\" fraction of the songs in the Charts dataset?\n",
        "\n",
        "Additionally, since we'll be combining multiple audio features datasets, there is no guarantee that those datasets share the same features, so\n",
        "\n",
        "2. What fields do the datasets share?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, since we want to find song features for as many of the songs in 'df_charts' as possible, let's start by\n",
        "# projecting df_charts by song title and artist name, which will uniquely identify each song, and then dropping duplicates\n",
        "df_charts_songs_artists = df_charts[['title', 'artist']].drop_duplicates()\n",
        "\n",
        "# Next, let's join the features datasets on song title and artist name and see what percentage of songs in charts_df\n",
        "# each song features dataset can provide features for\n",
        "\n",
        "# Clean extranneous characters from artist columns if necessary\n",
        "df_song_features_1['artists'] = df_song_features_1['artists'].str.replace('[', '').str.replace(']', '').str.replace(\"'\", '')\n",
        "df_song_features_5['artists'] = df_song_features_5['artists'].str.replace('[', '').str.replace(']', '').str.replace(\"'\", '')\n",
        "df_song_features_7['artists'] = df_song_features_7['artists'].str.replace(', ', '')\n",
        "df_song_features_10['artists'] = df_song_features_10['artists'].str.replace(', ', '')"
      ],
      "metadata": {
        "id": "zLjoplKkLYD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es9cOCyBb6IW"
      },
      "outputs": [],
      "source": [
        "# Rename song title \"title\" and \"artist\" columns in each dataframe and \n",
        "# create separate dataframes for features_7 and features_10, which each have three columns for each field for three different songs\n",
        "df_song_features_1 = df_song_features_1.rename(columns={'name': 'title', 'artists': 'artist'})\n",
        "# _song_features_2 already has fields 'title' and 'artist'\n",
        "df_song_features_3 = df_song_features_3.rename(columns={'Song Name': 'title', 'Artist': 'artist'})\n",
        "df_song_features_4 = df_song_features_4.rename(columns={'track_name': 'title', 'artists': 'artist'})\n",
        "df_song_features_5 = df_song_features_5.rename(columns={'name': 'title', 'artists': 'artist'})\n",
        "df_song_features_6 = df_song_features_6.rename(columns={'track_name': 'title', 'artist_name': 'artist'})\n",
        "df_song_features_8 = df_song_features_7.rename(columns={'t_name1': 'title', 'artists': 'artist'}).drop(columns=['t_name0', 't_name2', 't_dur0', 't_dur2', 't_dance0', 't_dance2', 't_energy0', 't_energy2', 't_key0', 't_key2', 't_mode0', 't_mode2', 't_speech0', 't_speech2', 't_acous0', 't_acous2', 't_ins0', 't_ins2', 't_live0', 't_live2', 't_val0', 't_val2', 't_tempo0', 't_tempo2', 't_sig0', 't_sig2'])\n",
        "df_song_features_9 = df_song_features_7.rename(columns={'t_name2': 'title', 'artists': 'artist'}).drop(columns=['t_name0', 't_name1', 't_dur0', 't_dur1', 't_dance0', 't_dance1', 't_energy0', 't_energy1', 't_key0', 't_key1', 't_mode0', 't_mode1', 't_speech0', 't_speech1', 't_acous0', 't_acous1', 't_ins0', 't_ins1', 't_live0', 't_live1', 't_val0', 't_val1', 't_tempo0', 't_tempo1', 't_sig0', 't_sig1'])\n",
        "df_song_features_7 = df_song_features_7.rename(columns={'t_name0': 'title', 'artists': 'artist'}).drop(columns=['t_name1', 't_name2', 't_dur1', 't_dur2', 't_dance1', 't_dance2', 't_energy1', 't_energy2', 't_key1', 't_key2', 't_mode1', 't_mode2', 't_speech1', 't_speech2', 't_acous1', 't_acous2', 't_ins1', 't_ins2', 't_live1', 't_live2', 't_val1', 't_val2', 't_tempo1', 't_tempo2', 't_sig1', 't_sig2'])\n",
        "df_song_features_11 = df_song_features_10.rename(columns={'t_name1': 'title', 'artists': 'artist'}).drop(columns=['t_name0', 't_name2', 't_dur0', 't_dur2', 't_dance0', 't_dance2', 't_energy0', 't_energy2', 't_key0', 't_key2', 't_mode0', 't_mode2', 't_speech0', 't_speech2', 't_acous0', 't_acous2', 't_ins0', 't_ins2', 't_live0', 't_live2', 't_val0', 't_val2', 't_tempo0', 't_tempo2', 't_sig0', 't_sig2'])\n",
        "df_song_features_12 = df_song_features_10.rename(columns={'t_name2': 'title', 'artists': 'artist'}).drop(columns=['t_name0', 't_name1', 't_dur0', 't_dur1', 't_dance0', 't_dance1', 't_energy0', 't_energy1', 't_key0', 't_key1', 't_mode0', 't_mode1', 't_speech0', 't_speech1', 't_acous0', 't_acous1', 't_ins0', 't_ins1', 't_live0', 't_live1', 't_val0', 't_val1', 't_tempo0', 't_tempo1', 't_sig0', 't_sig1'])\n",
        "df_song_features_10 = df_song_features_10.rename(columns={'t_name0': 'title', 'artists': 'artist'}).drop(columns=['t_name1', 't_name2', 't_dur1', 't_dur2', 't_dance1', 't_dance2', 't_energy1', 't_energy2', 't_key1', 't_key2', 't_mode1', 't_mode2', 't_speech1', 't_speech2', 't_acous1', 't_acous2', 't_ins1', 't_ins2', 't_live1', 't_live2', 't_val1', 't_val2', 't_tempo1', 't_tempo2', 't_sig1', 't_sig2'])\n",
        "\n",
        "# Project only the necessary columns from each feature dataset and also rename to maintain consistency\n",
        "features_1_projected = df_song_features_1[['title', 'artist']]\n",
        "features_2_projected = df_song_features_2[['title', 'artist']]\n",
        "features_3_projected = df_song_features_3[['title', 'artist']]\n",
        "features_4_projected = df_song_features_4[['title', 'artist']]\n",
        "features_5_projected = df_song_features_5[['title', 'artist']]\n",
        "features_6_projected = df_song_features_6[['title', 'artist']]\n",
        "features_7_projected = df_song_features_7[['title', 'artist']]\n",
        "features_8_projected = df_song_features_8[['title', 'artist']]\n",
        "features_9_projected = df_song_features_9[['title', 'artist']]\n",
        "features_10_projected = df_song_features_10[['title', 'artist']]\n",
        "features_11_projected = df_song_features_11[['title', 'artist']]\n",
        "features_12_projected = df_song_features_12[['title', 'artist']]\n",
        "all_songs_with_features = pd.concat([features_1_projected, features_2_projected, features_3_projected, features_4_projected, \n",
        "                                     features_5_projected, features_6_projected, features_7_projected, features_8_projected, \n",
        "                                     features_9_projected, features_10_projected, features_11_projected, features_12_projected], ignore_index=True).drop_duplicates()\n",
        "\n",
        "# Join on song title and artist name\n",
        "feature_matches = pd.merge(df_charts_songs_artists, all_songs_with_features, on=['title', 'artist'], how='inner')\n",
        "\n",
        "# Calculate the percentage of songs each features dataset was able to provide song features for\n",
        "match_percentage_combined = 100 * feature_matches.shape[0] / df_charts_songs_artists.shape[0]\n",
        "print(\"We are able to provide audio features for \" + str(round(match_percentage_combined,2)) + \"% of songs in df_charts,\"\\\n",
        "      \" for a total of \" + str(feature_matches.shape[0]) + \" out of \" + str(df_charts_songs_artists.shape[0]) + \" songs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWfoMYNn0xcx"
      },
      "source": [
        "Lets now see whether we can do any additional cleaning to boost our match percentage. Since there are many obscure songs in df_charts that have, say, reached chart position 200 in small countries like Latvia and Ecuador, let us limit our search to songs that charted highly in the United States, and see if any of those songs were unmatched in the features data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AAL49Tp0xcx"
      },
      "outputs": [],
      "source": [
        "non_matches = pd.merge(df_charts[df_charts['rank'] > 10][df_charts['region'] == 'United States'][['title', 'artist']], \n",
        "                                  all_songs_with_features, on=['title', 'artist'], how='left', indicator=True).drop_duplicates()\n",
        "non_matches = non_matches[non_matches['_merge'] == 'left_only']\n",
        "non_matches.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAkQD5ey0xcx"
      },
      "outputs": [],
      "source": [
        "# Does all_songs_with_features contain any of these songs but perhaps with a different format for title and artist?\n",
        "print(all_songs_with_features[all_songs_with_features['artist'] == 'NLE Choppa, Roddy Ricch'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixpQ3cAq0xcx"
      },
      "source": [
        "This suggests that when there is a featured artist, the ordering of the artist names in the features datasets may be the opposite of the ordering in the charts dataset. Lets look at the other row with a featured artist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdEeJDPN0xcx"
      },
      "outputs": [],
      "source": [
        "print(all_songs_with_features[all_songs_with_features['artist'] == \"Khalid, Summer Walker\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYxPCiZ00xcx"
      },
      "source": [
        "In this case, the featured artist is not included in the 'artist' column in the charts dataset, but is in the features datasets. In joins so far, we have been joining on 'artist' and 'title' to be sure to uniquely identify each song. But since these songs with featured artists have varying formats in the 'artist' column, but the same format in the 'title' column, and since they are sure to be uniquely identified just by song title, let us try to filter by songs that have \"(feat. \" in their title, and join the charts and features datasets on 'title'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvySHSIt0xcy"
      },
      "outputs": [],
      "source": [
        "charts_featured = df_charts_songs_artists[df_charts_songs_artists['title'].str.contains(\"\\(feat\\. \")][['title', 'artist']]\n",
        "featured_feature_matches = pd.merge(charts_featured, all_songs_with_features, on=['title'], how='inner').drop_duplicates(subset='title')\n",
        "featured_feature_matches.drop(columns=['artist_x'], inplace=True)\n",
        "featured_feature_matches.rename(columns={'artist_y': 'artist'}, inplace=True)\n",
        "feature_matches = pd.concat([feature_matches, featured_feature_matches], ignore_index=True).drop_duplicates()\n",
        "match_percentage_combined = 100 * feature_matches.shape[0] / df_charts_songs_artists.shape[0]\n",
        "print(\"We are able to provide audio features for \" + str(round(match_percentage_combined,2)) + \"% of songs in df_charts,\"\\\n",
        "      \" for a total of \" + str(feature_matches.shape[0]) + \" out of \" + str(df_charts_songs_artists.shape[0]) + \" songs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-MiLcop0xcy"
      },
      "source": [
        "Next, lets see what columns each of the features datasets share, and create one unified features dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([col for col in df_song_features_1.columns])\n",
        "print([col for col in df_song_features_2.columns])\n",
        "print([col for col in df_song_features_3.columns])\n",
        "print([col for col in df_song_features_4.columns])\n",
        "print([col for col in df_song_features_5.columns])\n",
        "print([col for col in df_song_features_6.columns])\n",
        "print([col for col in df_song_features_7.columns])\n",
        "print([col for col in df_song_features_8.columns])\n",
        "print([col for col in df_song_features_9.columns])\n",
        "print([col for col in df_song_features_10.columns])\n",
        "print([col for col in df_song_features_11.columns])\n",
        "print([col for col in df_song_features_12.columns])"
      ],
      "metadata": {
        "id": "lMiBMVWZD4xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common columns:\n",
        "\n",
        "title, artist, tempo, energy, danceability, liveness, valence, duration, acousticness, speechiness"
      ],
      "metadata": {
        "id": "e3RIRHuiRq0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_1_drop_cols = ['loudness', 'album', 'id', 'album_id', 'artist_ids', 'track_number', 'disc_number', 'explicit', 'key', 'mode', 'instrumentalness', 'time_signature', 'year', 'release_date']\n",
        "features_2_drop_cols = ['dB', 'year released', 'added', 'pop', 'top year', 'artist type', 'top genre']\n",
        "features_3_drop_cols = ['Chord', 'Loudness', 'Index', 'Highest Charting Position', 'Number of Times Charted', 'Week of Highest Charting', 'Streams', 'Artist Followers', 'Song ID', 'Genre', 'Release Date', 'Weeks Charted', 'Popularity']\n",
        "features_4_drop_cols = ['loudness', 'Unnamed: 0', 'track_id', 'album_name', 'popularity', 'explicit', 'key', 'mode', 'instrumentalness', 'time_signature', 'track_genre']\n",
        "features_5_drop_cols = ['loudness', 'year', 'explicit', 'id', 'instrumentalness', 'key', 'mode', 'popularity', 'release_date']\n",
        "features_6_drop_cols = ['loudness', 'genre', 'track_id', 'popularity', 'instrumentalness', 'key', 'mode', 'time_signature']\n",
        "features_7_drop_cols = ['id', 'name', 'release_date', 'total_tracks', 't_key0', 't_mode0', 't_ins0', 't_sig0', 'popularity']\n",
        "features_8_drop_cols = ['id', 'name', 'release_date', 'total_tracks', 't_key1', 't_mode1', 't_ins1', 't_sig1', 'popularity']\n",
        "features_9_drop_cols = ['id', 'name', 'release_date', 'total_tracks', 't_key2', 't_mode2', 't_ins2', 't_sig2', 'popularity']\n",
        "features_10_drop_cols = ['id', 'name', 'release_date', 'total_tracks', 't_key0', 't_mode0', 't_ins0', 't_sig0']\n",
        "features_11_drop_cols = ['id', 'name', 'release_date', 'total_tracks', 't_key1', 't_mode1', 't_ins1', 't_sig1']\n",
        "features_12_drop_cols = ['id', 'name', 'release_date', 'total_tracks', 't_key2', 't_mode2', 't_ins2', 't_sig2']\n",
        "\n",
        "features_2_rename_map = {'bpm': 'tempo', 'nrgy': 'energy', 'dnce': 'danceability', 'live': 'liveness', 'val': 'valence', 'dur': 'duration_ms', 'acous': 'acousticness', 'spch': 'speechiness'}\n",
        "features_3_rename_map = {'Danceability': 'danceability', 'Energy': 'energy', 'Speechiness': 'speechiness', 'Acousticness': 'acousticness', 'Liveness': 'liveness', 'Tempo': 'tempo', 'Duration (ms)': 'duration_ms', 'Valence': 'valence'}\n",
        "features_7_rename_map = {'t_dance0': 'danceability', 't_energy0': 'energy', 't_speech0': 'speechiness', 't_acous0': 'acousticness', 't_live0': 'liveness', 't_tempo0': 'tempo', 't_dur0': 'duration_ms', 't_val0': 'valence'}\n",
        "features_8_rename_map = {'t_dance1': 'danceability', 't_energy1': 'energy', 't_speech1': 'speechiness', 't_acous1': 'acousticness', 't_live1': 'liveness', 't_tempo1': 'tempo', 't_dur1': 'duration_ms', 't_val1': 'valence'}\n",
        "features_9_rename_map = {'t_dance2': 'danceability', 't_energy2': 'energy', 't_speech2': 'speechiness', 't_acous2': 'acousticness', 't_live2': 'liveness', 't_tempo2': 'tempo', 't_dur2': 'duration_ms', 't_val2': 'valence'}\n",
        "features_10_rename_map = {'t_dance0': 'danceability', 't_energy0': 'energy', 't_speech0': 'speechiness', 't_acous0': 'acousticness', 't_live0': 'liveness', 't_tempo0': 'tempo', 't_dur0': 'duration_ms', 't_val0': 'valence'}\n",
        "features_11_rename_map = {'t_dance1': 'danceability', 't_energy1': 'energy', 't_speech1': 'speechiness', 't_acous1': 'acousticness', 't_live1': 'liveness', 't_tempo1': 'tempo', 't_dur1': 'duration_ms', 't_val1': 'valence'}\n",
        "features_12_rename_map = {'t_dance2': 'danceability', 't_energy2': 'energy', 't_speech2': 'speechiness', 't_acous2': 'acousticness', 't_live2': 'liveness', 't_tempo2': 'tempo', 't_dur2': 'duration_ms', 't_val2': 'valence'}\n",
        "\n",
        "df_song_features_1 = df_song_features_1.drop(columns=features_1_drop_cols)\n",
        "df_song_features_2 = df_song_features_2.drop(columns=features_2_drop_cols).rename(columns=features_2_rename_map)\n",
        "df_song_features_3 = df_song_features_3.drop(columns=features_3_drop_cols).rename(columns=features_3_rename_map)\n",
        "df_song_features_4 = df_song_features_4.drop(columns=features_4_drop_cols)\n",
        "df_song_features_5 = df_song_features_5.drop(columns=features_5_drop_cols)\n",
        "df_song_features_6 = df_song_features_6.drop(columns=features_6_drop_cols)\n",
        "df_song_features_7 = df_song_features_7.drop(columns=features_7_drop_cols).rename(columns=features_7_rename_map)\n",
        "df_song_features_8 = df_song_features_8.drop(columns=features_8_drop_cols).rename(columns=features_8_rename_map)    \n",
        "df_song_features_9 = df_song_features_9.drop(columns=features_9_drop_cols).rename(columns=features_9_rename_map)\n",
        "df_song_features_10 = df_song_features_10.drop(columns=features_10_drop_cols).rename(columns=features_10_rename_map)\n",
        "df_song_features_11 = df_song_features_11.drop(columns=features_11_drop_cols).rename(columns=features_11_rename_map)\n",
        "df_song_features_12 = df_song_features_12.drop(columns=features_12_drop_cols).rename(columns=features_12_rename_map)"
      ],
      "metadata": {
        "id": "nbIKYoFzPD4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that all features dataframes have the same columns now:"
      ],
      "metadata": {
        "id": "9UIbeQP8YLb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(([col for col in df_song_features_1.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_2.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_3.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_4.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_5.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_6.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_7.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_8.columns.sort_values()])) \n",
        "print(([col for col in df_song_features_9.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_10.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_11.columns.sort_values()]))\n",
        "print(([col for col in df_song_features_12.columns.sort_values()]))"
      ],
      "metadata": {
        "id": "cZnIVmsiX0nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets concatenate all of these features dataframes into one and do an inner join with `all_songs_with_features` to get the final, combined features dataset"
      ],
      "metadata": {
        "id": "JxDepA63aIyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.concat([df_song_features_1, df_song_features_2, df_song_features_3, df_song_features_4, df_song_features_5, df_song_features_6, df_song_features_7, df_song_features_8, df_song_features_9, df_song_features_10, df_song_features_11, df_song_features_12], axis=0, ignore_index=True)\n",
        "df_features = df_features.dropna()\n",
        "df_features = pd.merge(df_features, feature_matches, on=['title', 'artist'], how='inner')\n",
        "df_features = df_features.drop_duplicates(subset=['title', 'artist'])\n",
        "df_features.reset_index(drop=True, inplace=True)\n",
        "df_features.head(100)  # inspect"
      ],
      "metadata": {
        "id": "K4puVSP5aYSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features.describe"
      ],
      "metadata": {
        "id": "qhw-hyW5fvK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9uFxr2sQGxY"
      },
      "source": [
        "# TikTok Popular Songs Dataset EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-JdIrzO08GS"
      },
      "outputs": [],
      "source": [
        "df_tiktok_19.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9txjEQY71b4g"
      },
      "outputs": [],
      "source": [
        "df_tiktok_20.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhbEd8of1cI5"
      },
      "outputs": [],
      "source": [
        "df_tiktok_21.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKJBDGC21cZF"
      },
      "outputs": [],
      "source": [
        "# Combine the tiktok datasets\n",
        "data_tiktok = [df_tiktok_19, df_tiktok_20, df_tiktok_21]\n",
        "df_tiktok_full = pd.concat(data_tiktok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AXhyqlrMnYp"
      },
      "outputs": [],
      "source": [
        "# Extract the track name and artist to check for the overlap\n",
        "df_tiktok_tracks = df_tiktok_full[['track_name', 'artist_name']]\n",
        "\n",
        "# Check number of rows\n",
        "df_tiktok_tracks.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBAyfruiUPD1"
      },
      "outputs": [],
      "source": [
        "# Merge with spotify features on track names only to check overlap\n",
        "df_tiktok_tracks_only = feature_matches.merge(df_tiktok_tracks.drop_duplicates(), left_on = ['title'], right_on=['track_name'], how='inner')\n",
        "\n",
        "# Check overlap\n",
        "df_tiktok_tracks_only.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C0fFJATUy4M"
      },
      "outputs": [],
      "source": [
        "# Review rows that didn't match to see if there's more clean-up that can be done \n",
        "df_tiktok_full_merge = feature_matches.merge(df_tiktok_tracks.drop_duplicates(), left_on = ['title'], right_on=['track_name'], how='outer', indicator = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnSpyq4oV8bu"
      },
      "outputs": [],
      "source": [
        "df_tiktok_full_merge.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BUzsCr2VuXv"
      },
      "outputs": [],
      "source": [
        "# Review rows that didn't match to see if there's more clean-up that can be done \n",
        "print(df_tiktok_full_merge[df_tiktok_full_merge['_merge'] != 'both'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxuu_bf2WYfF"
      },
      "outputs": [],
      "source": [
        "# do a check to see if I convert the track names to lower case, could I get more matches \n",
        "df_tiktok_full_merge.dropna(inplace = True)\n",
        "df_tiktok_full_merge['title_l'] = df_tiktok_full_merge.apply(lambda x : x['title'].lower(), axis =1)\n",
        "df_tiktok_full_merge['track_name_l'] = df_tiktok_full_merge.apply(lambda x : x['track_name'].lower(), axis =1)\n",
        "\n",
        "print(df_tiktok_full_merge[(df_tiktok_full_merge['title_l'] == df_tiktok_full_merge['track_name_l']) & (df_tiktok_full_merge['_merge'] != 'both')])\n",
        "\n",
        "# prints an empty dataframe so the conclusion is that no I can't"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evjfggiCWtcD"
      },
      "outputs": [],
      "source": [
        "# Create a match column to indicate cases where the tiktok artist name can be found as a substring in the spotify artist column \n",
        "df_tiktok_tracks_only['match'] = df_tiktok_tracks_only.apply(lambda x: x['artist_name'].lower().find(x['artist'].lower()), axis=1).ge(0)\n",
        "\n",
        "# Create a match column to indicate cases where the spotify artist column can be found as a substring in the tiktok artist name \n",
        "df_tiktok_tracks_only['match_2'] = df_tiktok_tracks_only.apply(lambda x: x['artist'].lower().find(x['artist_name'].lower()), axis=1).ge(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef71rA5qiRYD"
      },
      "outputs": [],
      "source": [
        "# review data to see which rows have matched\n",
        "print(df_tiktok_tracks_only[df_tiktok_tracks_only['match'] |df_tiktok_tracks_only['match_2']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9khMP9ZTkFg"
      },
      "outputs": [],
      "source": [
        "# review data to see which rows have not matched\n",
        "print(df_tiktok_tracks_only[(df_tiktok_tracks_only['match'] == False) & (df_tiktok_tracks_only['match_2'] == False)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMJjLZcVijGK"
      },
      "outputs": [],
      "source": [
        "# check the rows where the artists names aren't an exact match - for visual inspection \n",
        "df_tiktok_tracks_only.loc[(df_tiktok_tracks_only['artist'] != df_tiktok_tracks_only['artist_name']) & (df_tiktok_tracks_only['match'] |df_tiktok_tracks_only['match_2'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VbUNXhYjJKW"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe of overlapping songs based on the two matches colums and drop duplicates\n",
        "df_tiktok_matches_final = df_tiktok_tracks_only.loc[(df_tiktok_tracks_only['match'] |df_tiktok_tracks_only['match_2'])]\n",
        "\n",
        "# Check the shape of the df \n",
        "df_tiktok_matches_final.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbwjCLEOTJzD"
      },
      "outputs": [],
      "source": [
        "# spot check an artist to see if the name matching looks appropriate \n",
        "df_tiktok_matches_final.loc[(df_tiktok_matches_final['artist_name'] == \"Justin Bieber\" )|( df_tiktok_matches_final['artist'] == \"Justin Bieber\" )]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrdLP4IVPxZZ"
      },
      "outputs": [],
      "source": [
        "# drop rows that are no longer needed\n",
        "df_tiktok_matches_final.drop(['match', 'match_2', 'track_name', 'artist_name'], inplace =True, axis =1)\n",
        "\n",
        "# add a column to indicate tiktok popularity \n",
        "df_tiktok_matches_final= df_tiktok_matches_final.assign(tiktok_pop = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSScxkw6RHrq"
      },
      "outputs": [],
      "source": [
        "df_tiktok_matches_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7ZBdyHGRaib"
      },
      "outputs": [],
      "source": [
        "df_tiktok_matches_final.groupby(['tiktok_pop']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eekt5MsyjswP"
      },
      "source": [
        "# Genius Lyrics Dataset Creation and EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qEn8QjXbcGi"
      },
      "outputs": [],
      "source": [
        "!pip install lyricsgenius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ym966T4Crmo"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "feature_matches.to_csv('combined_features.csv') \n",
        "files.download('combined_features.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNiMjD2tu5_c"
      },
      "outputs": [],
      "source": [
        "import lyricsgenius\n",
        "import os\n",
        "import spacy\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37JKFZI3n8Fu"
      },
      "outputs": [],
      "source": [
        "client_id = 'TS15U5iwbWLGkhfGFVqnOuDA9mVjJhhLlXpJDYai6nm79S9JWFzznlsQN5dCFuZG'\n",
        "client_secret = 'SOhrXQxD9YZ2RxBQwR-wwu5Zbxh6UgkfuIEaUJltx9L9h8aynN5zZ9Jsm1JNlh_5Npu_uev1MKorJV_A6MVYKw'\n",
        "access_token = 'US00oQ6_8lkhwRjHAOudB62bruf1B3JGOGuHR8V8zeawxpoc8fcA9QGXQ3bhYWu-'\n",
        "website_url = 'https://github.com/Joseph-Willem-Ricci/5450-final-project'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7-Si0qot9Bp"
      },
      "outputs": [],
      "source": [
        "\"\"\"genius = lyricsgenius.Genius(access_token)\n",
        "artist = genius.search_artist('Andy Shauf')\n",
        "artist.save_lyrics()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD1gD1uxuw4n"
      },
      "outputs": [],
      "source": [
        "\"\"\"api = lyricsgenius.Genius(access_token)\n",
        "artist = api.artist(380491)\n",
        "print(artist)\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPZfntq-CKy2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "#stopword_en = nltk.corpus.stopwords.words('english')\n",
        "#stopword_es = nltk.corpus.stopwords.words('spanish')\n",
        "#stopword = stopword_en + stopword_es\n",
        "stopwords = set(stopwords.words(['english', 'spanish', 'german','french']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywy08Es-DH9D"
      },
      "outputs": [],
      "source": [
        "!!kaggle datasets download -d joannecrean/spotify-songs-lyrics  #FIXME: Generalize this to run on anybody's colab\n",
        "!unzip /content/spotify-songs-lyrics.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z588WsRN0Sek"
      },
      "outputs": [],
      "source": [
        "df_lyrics = pd.read_csv('all_song_data_complete.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ5P__YKtqWf"
      },
      "outputs": [],
      "source": [
        "sensitive_words = pd.read_csv('sensitive_words.csv')\n",
        "sensitive_words =sensitive_words.values.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFO_EiBGCUsd"
      },
      "outputs": [],
      "source": [
        "def tokenize_content(content):\n",
        "  content = content.lower() #convert to lowercase\n",
        "  content_tokens = nltk.word_tokenize(content) # tokenise\n",
        "  alpha_tokens = [w for w in content_tokens if w.isalpha()] # keep alpha tokens\n",
        "  stop_tokens = [t for t in alpha_tokens if not t in stopwords] #remove if stopword\n",
        "  final_tokens = [s for s in stop_tokens if not s in sensitive_words] #remove if sensitive\n",
        "  #print(final_tokens)\n",
        "  return final_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxDXD3obDweO"
      },
      "outputs": [],
      "source": [
        "df_lyrics.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24JvqH8XEJv0"
      },
      "outputs": [],
      "source": [
        "len(df_lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqg3iEZMzy-w"
      },
      "outputs": [],
      "source": [
        "df_lyrics.loc[df_lyrics['title'] == 'You Make My Dreams (Come True)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0PWn_-EECd_"
      },
      "outputs": [],
      "source": [
        "df_lyrics.dropna(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAE_iPMk2SH1"
      },
      "outputs": [],
      "source": [
        "df_lyrics.loc[df_lyrics['song URL'] == 'https://genius.com/Gerald-haywood-2018-haywoodindahood-listening-log-annotated']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9P6l1nK0XqX"
      },
      "outputs": [],
      "source": [
        "# clean up by dropping rows that aren't lyrics\n",
        "df_lyrics = df_lyrics[~df_lyrics['song URL'].str.contains('annotated')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KblsyvnF9BHy"
      },
      "outputs": [],
      "source": [
        "# remove the intro text before the lyrics \n",
        "df_lyrics['lyrics'] = [re.sub('^.*Lyrics', '', x) for x in df_lyrics['lyrics']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-26t2NwUv0CY"
      },
      "outputs": [],
      "source": [
        "#remove rows where the URL is not correct so the lyrics are not accurate\n",
        "\n",
        "df_lyrics['clean URL'] = df_lyrics['song URL'].str.replace('-', '').str.lower()\n",
        "df_lyrics['clean artist'] = df_lyrics['artist'].str.replace(' ', '').str.lower()\n",
        "\n",
        "df_lyrics['URL letters'] = df_lyrics['clean URL'].str.extract(r'https://genius\\.com/(\\w{2})')\n",
        "\n",
        "#print(df_lyrics.head(10))\n",
        "\n",
        "df_lyrics = df_lyrics.loc[df_lyrics['URL letters'] == df_lyrics['clean artist'].str[:2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY0h-1Hn9R9o"
      },
      "outputs": [],
      "source": [
        "df_lyrics.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJJGsOi-4gYy"
      },
      "outputs": [],
      "source": [
        "len(df_lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kXjFyE9apEY"
      },
      "outputs": [],
      "source": [
        "df_lyrics.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4chSLK3zAel"
      },
      "outputs": [],
      "source": [
        "#df_lyrics_clean = df_lyrics.apply(lambda x: x['Unnamed: 0'] , axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Rx6KfHECiu0"
      },
      "outputs": [],
      "source": [
        "df_lyrics['tokenized'] = df_lyrics.apply(lambda x: tokenize_content(x.lyrics), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2amPvUbLEIQg"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def retrieve_sentiment(content):\n",
        "  return sia.polarity_scores(content)['compound']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrWOeSiLEiDW"
      },
      "outputs": [],
      "source": [
        "df_lyrics['sentiment'] = df_lyrics.apply(lambda x: retrieve_sentiment(x.lyrics), axis=1)\n",
        "df_lyrics_positive = df_lyrics.sort_values(by = ['sentiment'], ascending = False)\n",
        "df_lyrics_positive.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEU9M2g5jswR"
      },
      "outputs": [],
      "source": [
        "df_lyrics_negative = df_lyrics.sort_values(by = ['sentiment'])\n",
        "df_lyrics_negative.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dah5lt4YjswS"
      },
      "outputs": [],
      "source": [
        "def add_spacy_data(dataset, feature_column):\n",
        "    '''\n",
        "    Grabs the verb, adverb, noun, and stop word Parts of Speech (POS) \n",
        "    tokens and pushes them into a new dataset. returns an \n",
        "    enriched dataset.\n",
        "    \n",
        "    Parameters:\n",
        "    \n",
        "    dataset (dataframe): the dataframe to parse\n",
        "    feature_column (string): the column to parse in the dataset.\n",
        "    \n",
        "    Returns: \n",
        "    dataframe\n",
        "    '''\n",
        "    \n",
        "    verbs = []\n",
        "    nouns = []\n",
        "    adverbs = []\n",
        "    corpus = []\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    ##\n",
        "    for i in range (0, len(dataset)):\n",
        "        print(\"Extracting verbs and topics from record {} of {}\".format(i+1, len(dataset)), end = \"\\r\")\n",
        "        song = dataset.iloc[i][feature_column]\n",
        "        doc = nlp(song)\n",
        "        spacy_dataframe = pd.DataFrame()\n",
        "        for token in doc:\n",
        "            if token.lemma_ == \"-PRON-\":\n",
        "                    lemma = token.text\n",
        "            else:\n",
        "                lemma = token.lemma_\n",
        "            row = {\n",
        "                \"Word\": token.text,\n",
        "                \"Lemma\": lemma,\n",
        "                \"PoS\": token.pos_,\n",
        "                \"Stop Word\": token.is_stop\n",
        "            }\n",
        "            spacy_dataframe = spacy_dataframe.append(row, ignore_index = True)\n",
        "        verbs.append(\" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"VERB\"].values))\n",
        "        nouns.append(\" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"NOUN\"].values))\n",
        "        adverbs.append(\" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"ADV\"].values))\n",
        "        corpus_clean = \" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"Stop Word\"] == False].values)\n",
        "        corpus_clean = re.sub(r'[^A-Za-z0-9]+', ' ', corpus_clean)   \n",
        "        corpus.append(corpus_clean)\n",
        "    dataset['verbs'] = verbs\n",
        "    dataset['nouns'] = nouns\n",
        "    dataset['adverbs'] = adverbs\n",
        "    dataset['corpus'] = corpus\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJIBdKkGwT3F"
      },
      "outputs": [],
      "source": [
        "# alt spacy dataset\n",
        "\"\"\"\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "    ##\n",
        "    def extract_spacy_data(song):\n",
        "        doc = nlp(song)\n",
        "        spacy_dataframe = pd.DataFrame([{\n",
        "            \"Word\": token.text,\n",
        "            \"Lemma\": token.lemma_ if token.lemma_ != \"-PRON-\" else token.text,\n",
        "            \"PoS\": token.pos_,\n",
        "            \"Stop Word\": token.is_stop\n",
        "        } for token in doc])\n",
        "        verbs = \" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"VERB\"].values)\n",
        "        nouns = \" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"NOUN\"].values)\n",
        "        adverbs = \" \".join(spacy_dataframe[\"Lemma\"][spacy_dataframe[\"PoS\"] == \"ADV\"].values)\n",
        "        corpus_clean = \" \".join([token.lemma_ if token.lemma_ != \"-PRON-\" else token.text\n",
        "                                 for token in doc if not token.is_stop])\n",
        "        corpus_clean = re.sub(r'[^A-Za-z0-9]+', ' ', corpus_clean)\n",
        "        return verbs, nouns, adverbs, corpus_clean\n",
        "    \n",
        "    dataset[['verbs', 'nouns', 'adverbs', 'corpus']] = dataset[feature_column].apply(\n",
        "        lambda x: pd.Series(extract_spacy_data(x)), axis=1)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UAyj1VziQ3r"
      },
      "outputs": [],
      "source": [
        "\"\"\"df_lyrics_words = add_spacy_data(df_lyrics, 'lyrics')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGwz1W7Fu4xl"
      },
      "outputs": [],
      "source": [
        "\"\"\"df_lyrics_words.head(5)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJD9L0s-uM-j"
      },
      "outputs": [],
      "source": [
        "#df_lyrics_words = df_lyrics_words.drop(columns = ['Unnamed: 0'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIa3VED9uTHu"
      },
      "outputs": [],
      "source": [
        "\"\"\"word_counts = []\n",
        "unique_word_counts = []\n",
        "for i in range (0, len(df_lyrics_words)):\n",
        "    word_counts.append(len(df_lyrics_words.iloc[i]['lyrics'].split()))\n",
        "    unique_word_counts.append(len(set(df_lyrics_words.iloc[i]['lyrics'].split())))\n",
        "df_lyrics_words['word counts'] = word_counts\n",
        "df_lyrics_words['unique word counts'] = unique_word_counts\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfaHuJ1aR0In"
      },
      "outputs": [],
      "source": [
        "\"\"\"df_lyrics_words['common noun']= df_lyrics_words.apply(lambda x: x['nouns'].value_counts().idxmax())\n",
        "df_lyrics_words['common verb']= df_lyrics_words.apply(lambda x: x['verbs'].value_counts().idxmax())\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QY-m_yWCXJw"
      },
      "outputs": [],
      "source": [
        "\"\"\"df_lyrics_ready = df_lyrics_words[['title', 'artist', 'sentiment', 'word count', 'unique word count', 'common noun', 'common verb']]\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RZX6lNwo17Q"
      },
      "source": [
        "# Creating Final Dataset and EDA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5BVJcojpIXl"
      },
      "outputs": [],
      "source": [
        "\"\"\"df_features_lyrics =feature_matches.merge(df_lyrics_ready, left_on = ['title'], right_on = ['title'], how = 'inner')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW-aMO5hphew"
      },
      "outputs": [],
      "source": [
        "\"\"\"df_features_lyrics_tiktok = df_features_lyrics.merge(df_tiktok_matches_final, left_on = ['title'], right_on = ['title'], how = 'inner')\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}